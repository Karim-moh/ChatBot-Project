{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)  # Change to DEBUG for more details\n",
    "\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.eval()\n",
    "resnet50 = torch.nn.Sequential(*(list(resnet50.children())[:-1]))\n",
    "\n",
    "# Image preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize NLP models\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def clean_description(desc):\n",
    "    non_facial_keywords = r'\\b(shirt|jeans|pants|shoes|hat|scarf|jacket|coat)\\b'\n",
    "    clean_desc = re.sub(non_facial_keywords, '', desc, flags=re.IGNORECASE)\n",
    "    return re.sub(r\"\\s+\", \" \", clean_desc).strip()\n",
    "\n",
    "def extract_text_features(text):\n",
    "    text = clean_description(text)\n",
    "\n",
    "    feature_list = [\n",
    "        'male', 'female', 'young', 'middle-aged', 'elderly',\n",
    "        'blonde hair', 'brown hair', 'black hair', 'grey hair', 'white hair', 'red hair',\n",
    "        'blue eyes', 'green eyes', 'brown eyes', 'hazel eyes',\n",
    "        'bald', 'white', 'black', 'asian', 'hispanic', 'indian',\n",
    "        'tall', 'short', 'overweight', 'slim'\n",
    "    ]\n",
    "\n",
    "    logging.info(f\"Processing text: '{text}'\")\n",
    "    results = classifier(text, feature_list, multi_label=True)\n",
    "\n",
    "    # Set a higher confidence threshold to avoid conflicting features\n",
    "    confidence_threshold = 0.7\n",
    "    attributes = {\n",
    "        'sex': None,\n",
    "        'age': None,\n",
    "        'hair': None,\n",
    "        'eyes': None,\n",
    "        'height': None,\n",
    "        'race': None,\n",
    "        'weight': None\n",
    "    }\n",
    "\n",
    "    # Temporary dictionary to hold possible conflicting features\n",
    "    temp_attributes = {\n",
    "        'hair': [],\n",
    "        'age': [],\n",
    "        'height': []\n",
    "    }\n",
    "\n",
    "    for label, score in zip(results['labels'], results['scores']):\n",
    "        if score > confidence_threshold:\n",
    "            logging.debug(f\"Identified feature: {label} with confidence {score}\")\n",
    "            if label in ['male', 'female']:\n",
    "                attributes['sex'] = label\n",
    "            elif label in ['young', 'middle-aged', 'elderly']:\n",
    "                temp_attributes['age'].append((label, score))  # Collect age-related features\n",
    "            elif 'hair' in label:\n",
    "                temp_attributes['hair'].append((label.split()[0], score))  # Collect hair-related features\n",
    "            elif 'eyes' in label:\n",
    "                attributes['eyes'] = label.split()[0]\n",
    "            elif label in ['tall', 'short']:\n",
    "                temp_attributes['height'].append((label, score))  # Collect height-related features\n",
    "            elif label in ['overweight', 'slim']:\n",
    "                attributes['weight'] = label\n",
    "            elif label in ['white', 'black', 'asian', 'hispanic', 'indian']:\n",
    "                attributes['race'] = label\n",
    "\n",
    "    # Resolve conflicts by taking the feature with the highest confidence\n",
    "    if temp_attributes['hair']:\n",
    "        attributes['hair'] = max(temp_attributes['hair'], key=lambda x: x[1])[0]\n",
    "    if temp_attributes['age']:\n",
    "        attributes['age'] = max(temp_attributes['age'], key=lambda x: x[1])[0]\n",
    "    if temp_attributes['height']:\n",
    "        attributes['height'] = max(temp_attributes['height'], key=lambda x: x[1])[0]\n",
    "\n",
    "    logging.info(f\"Extracted features: {attributes}\")\n",
    "    return attributes\n",
    "\n",
    "\n",
    "def extract_image_features(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = preprocess(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = resnet50(img_tensor).squeeze().cpu().numpy()\n",
    "    return features\n",
    "\n",
    "def extract_features_for_samples(samples_folder):\n",
    "    image_features = {}\n",
    "    for filename in os.listdir(samples_folder):\n",
    "        image_path = os.path.join(samples_folder, filename)\n",
    "        if os.path.isfile(image_path):\n",
    "            features = extract_image_features(image_path)\n",
    "            image_features[filename] = features\n",
    "    return image_features\n",
    "\n",
    "def get_text_embedding(features):\n",
    "    description = \" \".join([f\"{key}: {value}\" for key, value in features.items() if value])\n",
    "    embedding = sentence_model.encode(description)\n",
    "    return embedding\n",
    "\n",
    "def compare_embeddings(text_embedding, image_embeddings):\n",
    "    # Project text_embedding to the same dimension as image_embeddings\n",
    "    text_embedding_projected = np.random.rand(image_embeddings.shape[1])\n",
    "    text_embedding_projected[:text_embedding.shape[0]] = text_embedding\n",
    "\n",
    "    similarities = cosine_similarity([text_embedding_projected], image_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:3]\n",
    "    return top_indices, similarities[top_indices]\n",
    "\n",
    "\n",
    "\n",
    "def filter_person_df_with_images(person_df, samples_folder):\n",
    "    \"\"\"\n",
    "    Filter the person DataFrame to only include entries for which\n",
    "    corresponding image files exist in the samples folder.\n",
    "    \"\"\"\n",
    "    existing_images = set(os.path.splitext(f)[0] for f in os.listdir(samples_folder) if f.endswith('.jpg'))\n",
    "    return person_df[person_df['id'].astype(str).isin(existing_images)]\n",
    "\n",
    "get_text_embedding\n",
    "\n",
    "\n",
    "\n",
    "def match_description_to_images(description, samples_folder, person_df):\n",
    "\n",
    "    person_df = filter_person_df_with_images(person_df, samples_folder)\n",
    "\n",
    "\n",
    "    # Extract text features\n",
    "    text_features = extract_text_features(description)\n",
    "\n",
    "    # Filter person_df based on extracted features\n",
    "    filtered_df = person_df.copy()\n",
    "\n",
    "    if text_features['race']:\n",
    "        filtered_df = filtered_df[filtered_df['race'].str.lower() == text_features['race'].lower()]\n",
    "\n",
    "    # Fix: Replace 'gender' with 'sex'\n",
    "    if text_features['sex']:\n",
    "        filtered_df = filtered_df[filtered_df['sex'].str.lower() == text_features['sex'].lower()]\n",
    "\n",
    "    if text_features['hair']:\n",
    "        filtered_df = filtered_df[filtered_df['hair'].str.lower() == text_features['hair'].lower()]\n",
    "\n",
    "    if text_features['eyes']:\n",
    "        filtered_df = filtered_df[filtered_df['eyes'].str.lower() == text_features['eyes'].lower()]\n",
    "\n",
    "    # Extract image features for filtered persons\n",
    "    image_features = {}\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        image_path = os.path.join(samples_folder, f\"{row['id']}.jpg\")\n",
    "        if os.path.isfile(image_path):\n",
    "            features = extract_image_features(image_path)\n",
    "            image_features[row['id']] = features\n",
    "\n",
    "    if not image_features:\n",
    "        return []  # No matches found\n",
    "\n",
    "    # Compare text features with image features\n",
    "    text_embedding = get_text_embedding(text_features)\n",
    "    image_embeddings = np.array(list(image_features.values()))\n",
    "    image_ids = list(image_features.keys())\n",
    "\n",
    "    top_indices, similarities = compare_embeddings(text_embedding, image_embeddings)\n",
    "\n",
    "    # Get top 3 matches\n",
    "    top_matches = []\n",
    "    for idx, similarity in zip(top_indices[:3], similarities[:3]):  # Ensure we always get 3 matches if available\n",
    "        image_id = image_ids[idx]\n",
    "        person_info = filtered_df[filtered_df['id'].astype(str) == str(image_id)].iloc[0].to_dict()\n",
    "\n",
    "        match_info = {\n",
    "            'image_name': f\"{image_id}.jpg\",\n",
    "            'image_path': os.path.join(samples_folder, f\"{image_id}.jpg\"),\n",
    "            'similarity': similarity,\n",
    "            'person_info': person_info\n",
    "        }\n",
    "        top_matches.append(match_info)\n",
    "\n",
    "    return top_matches\n",
    "\n",
    "def display_images(top_matches):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle(\"Top 3 Matched Images\", fontsize=16)\n",
    "\n",
    "    for i, match in enumerate(top_matches):\n",
    "        img = Image.open(match['image_path'])\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Match {i+1}\\nSimilarity: {match['similarity']:.2f}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    samples_folder = '/content/drive/MyDrive/sample_2'\n",
    "    person_df = pd.read_csv('/content/drive/MyDrive/person.csv', delimiter=';')\n",
    "\n",
    "    while True:\n",
    "        description = input(\"Enter a description of the person you're looking for (or 'quit' to exit): \")\n",
    "        if description.lower() == 'quit':\n",
    "            print(\"Thank you for using the person search system. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        top_matches = match_description_to_images(description, samples_folder, person_df)\n",
    "\n",
    "        if not top_matches:\n",
    "            print(\"No matches found for the given description.\")\n",
    "        else:\n",
    "            print(\"\\nTop 3 matched images:\")\n",
    "            for i, match in enumerate(top_matches, 1):\n",
    "                print(f\"\\n{i}. Image: {match['image_name']}\")\n",
    "                print(f\"   Similarity Score: {match['similarity']:.2f}\")\n",
    "                print(\"   Person Information:\")\n",
    "                for key, value in match['person_info'].items():\n",
    "                    print(f\"   - {key.capitalize()}: {value}\")\n",
    "\n",
    "        # Display the images\n",
    "        display_images(top_matches)\n",
    "\n",
    "    print(\"\\n\")  # Add a newline for better readability\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)  # Change to DEBUG for more details\n",
    "\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.eval()\n",
    "resnet50 = torch.nn.Sequential(*(list(resnet50.children())[:-1]))\n",
    "\n",
    "# Image preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize NLP models\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def clean_description(desc):\n",
    "    non_facial_keywords = r'\\b(shirt|jeans|pants|shoes|hat|scarf|jacket|coat)\\b'\n",
    "    clean_desc = re.sub(non_facial_keywords, '', desc, flags=re.IGNORECASE)\n",
    "    return re.sub(r\"\\s+\", \" \", clean_desc).strip()\n",
    "\n",
    "def extract_text_features(text):\n",
    "    text = clean_description(text)\n",
    "\n",
    "    feature_list = [\n",
    "        'male', 'female', 'young', 'middle-aged', 'elderly',\n",
    "        'blonde hair', 'brown hair', 'black hair', 'grey hair', 'white hair', 'red hair',\n",
    "        'blue eyes', 'green eyes', 'brown eyes', 'hazel eyes',\n",
    "        'bald', 'white', 'black', 'asian', 'hispanic', 'indian',\n",
    "        'tall', 'short', 'overweight', 'slim'\n",
    "    ]\n",
    "\n",
    "    logging.info(f\"Processing text: '{text}'\")\n",
    "    results = classifier(text, feature_list, multi_label=True)\n",
    "\n",
    "    # Set a higher confidence threshold to avoid conflicting features\n",
    "    confidence_threshold = 0.7\n",
    "    attributes = {\n",
    "        'sex': None,\n",
    "        'age': None,\n",
    "        'hair': None,\n",
    "        'eyes': None,\n",
    "        'height': None,\n",
    "        'race': None,\n",
    "        'weight': None\n",
    "    }\n",
    "\n",
    "    # Temporary dictionary to hold possible conflicting features\n",
    "    temp_attributes = {\n",
    "        'hair': [],\n",
    "        'age': [],\n",
    "        'height': []\n",
    "    }\n",
    "\n",
    "    for label, score in zip(results['labels'], results['scores']):\n",
    "        if score > confidence_threshold:\n",
    "            logging.debug(f\"Identified feature: {label} with confidence {score}\")\n",
    "            if label in ['male', 'female']:\n",
    "                attributes['sex'] = label\n",
    "            elif label in ['young', 'middle-aged', 'elderly']:\n",
    "                temp_attributes['age'].append((label, score))  # Collect age-related features\n",
    "            elif 'hair' in label:\n",
    "                temp_attributes['hair'].append((label.split()[0], score))  # Collect hair-related features\n",
    "            elif 'eyes' in label:\n",
    "                attributes['eyes'] = label.split()[0]\n",
    "            elif label in ['tall', 'short']:\n",
    "                temp_attributes['height'].append((label, score))  # Collect height-related features\n",
    "            elif label in ['overweight', 'slim']:\n",
    "                attributes['weight'] = label\n",
    "            elif label in ['white', 'black', 'asian', 'hispanic', 'indian']:\n",
    "                attributes['race'] = label\n",
    "\n",
    "    # Resolve conflicts by taking the feature with the highest confidence\n",
    "    if temp_attributes['hair']:\n",
    "        attributes['hair'] = max(temp_attributes['hair'], key=lambda x: x[1])[0]\n",
    "    if temp_attributes['age']:\n",
    "        attributes['age'] = max(temp_attributes['age'], key=lambda x: x[1])[0]\n",
    "    if temp_attributes['height']:\n",
    "        attributes['height'] = max(temp_attributes['height'], key=lambda x: x[1])[0]\n",
    "\n",
    "    logging.info(f\"Extracted features: {attributes}\")\n",
    "    return attributes\n",
    "\n",
    "\n",
    "def extract_image_features(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = preprocess(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = resnet50(img_tensor).squeeze().cpu().numpy()\n",
    "    return features\n",
    "\n",
    "def extract_features_for_samples(samples_folder):\n",
    "    image_features = {}\n",
    "    for filename in os.listdir(samples_folder):\n",
    "        image_path = os.path.join(samples_folder, filename)\n",
    "        if os.path.isfile(image_path):\n",
    "            features = extract_image_features(image_path)\n",
    "            image_features[filename] = features\n",
    "    return image_features\n",
    "\n",
    "def get_text_embedding(features):\n",
    "    description = \" \".join([f\"{key}: {value}\" for key, value in features.items() if value])\n",
    "    embedding = sentence_model.encode(description)\n",
    "    return embedding\n",
    "\n",
    "def compare_embeddings(text_embedding, image_embeddings):\n",
    "    # Project text_embedding to the same dimension as image_embeddings\n",
    "    text_embedding_projected = np.random.rand(image_embeddings.shape[1])\n",
    "    text_embedding_projected[:text_embedding.shape[0]] = text_embedding\n",
    "\n",
    "    similarities = cosine_similarity([text_embedding_projected], image_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:3]\n",
    "    return top_indices, similarities[top_indices]\n",
    "\n",
    "\n",
    "\n",
    "def filter_person_df_with_images(person_df, samples_folder):\n",
    "    \"\"\"\n",
    "    Filter the person DataFrame to only include entries for which\n",
    "    corresponding image files exist in the samples folder.\n",
    "    \"\"\"\n",
    "    existing_images = set(os.path.splitext(f)[0] for f in os.listdir(samples_folder) if f.endswith('.jpg'))\n",
    "    return person_df[person_df['id'].astype(str).isin(existing_images)]\n",
    "\n",
    "get_text_embedding\n",
    "\n",
    "\n",
    "\n",
    "def match_description_to_images(description, samples_folder, person_df):\n",
    "\n",
    "    person_df = filter_person_df_with_images(person_df, samples_folder)\n",
    "\n",
    "\n",
    "    # Extract text features\n",
    "    text_features = extract_text_features(description)\n",
    "\n",
    "    # Filter person_df based on extracted features\n",
    "    filtered_df = person_df.copy()\n",
    "\n",
    "    if text_features['race']:\n",
    "        filtered_df = filtered_df[filtered_df['race'].str.lower() == text_features['race'].lower()]\n",
    "\n",
    "    # Fix: Replace 'gender' with 'sex'\n",
    "    if text_features['sex']:\n",
    "        filtered_df = filtered_df[filtered_df['sex'].str.lower() == text_features['sex'].lower()]\n",
    "\n",
    "    if text_features['hair']:\n",
    "        filtered_df = filtered_df[filtered_df['hair'].str.lower() == text_features['hair'].lower()]\n",
    "\n",
    "    if text_features['eyes']:\n",
    "        filtered_df = filtered_df[filtered_df['eyes'].str.lower() == text_features['eyes'].lower()]\n",
    "\n",
    "    # Extract image features for filtered persons\n",
    "    image_features = {}\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        image_path = os.path.join(samples_folder, f\"{row['id']}.jpg\")\n",
    "        if os.path.isfile(image_path):\n",
    "            features = extract_image_features(image_path)\n",
    "            image_features[row['id']] = features\n",
    "\n",
    "    if not image_features:\n",
    "        return []  # No matches found\n",
    "\n",
    "    # Compare text features with image features\n",
    "    text_embedding = get_text_embedding(text_features)\n",
    "    image_embeddings = np.array(list(image_features.values()))\n",
    "    image_ids = list(image_features.keys())\n",
    "\n",
    "    top_indices, similarities = compare_embeddings(text_embedding, image_embeddings)\n",
    "\n",
    "    # Get top 3 matches\n",
    "    top_matches = []\n",
    "    for idx, similarity in zip(top_indices[:3], similarities[:3]):  # Ensure we always get 3 matches if available\n",
    "        image_id = image_ids[idx]\n",
    "        person_info = filtered_df[filtered_df['id'].astype(str) == str(image_id)].iloc[0].to_dict()\n",
    "\n",
    "        match_info = {\n",
    "            'image_name': f\"{image_id}.jpg\",\n",
    "            'image_path': os.path.join(samples_folder, f\"{image_id}.jpg\"),\n",
    "            'similarity': similarity,\n",
    "            'person_info': person_info\n",
    "        }\n",
    "        top_matches.append(match_info)\n",
    "\n",
    "    return top_matches\n",
    "\n",
    "def display_images(top_matches):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle(\"Top 3 Matched Images\", fontsize=16)\n",
    "\n",
    "    for i, match in enumerate(top_matches):\n",
    "        img = Image.open(match['image_path'])\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Match {i+1}\\nSimilarity: {match['similarity']:.2f}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    samples_folder = '/content/drive/MyDrive/sample_2'\n",
    "    person_df = pd.read_csv('/content/drive/MyDrive/person.csv', delimiter=';')\n",
    "\n",
    "    while True:\n",
    "        description = input(\"Enter a description of the person you're looking for (or 'quit' to exit): \")\n",
    "        if description.lower() == 'quit':\n",
    "            print(\"Thank you for using the person search system. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        top_matches = match_description_to_images(description, samples_folder, person_df)\n",
    "\n",
    "        if not top_matches:\n",
    "            print(\"No matches found for the given description.\")\n",
    "        else:\n",
    "            print(\"\\nTop 3 matched images:\")\n",
    "            for i, match in enumerate(top_matches, 1):\n",
    "                print(f\"\\n{i}. Image: {match['image_name']}\")\n",
    "                print(f\"   Similarity Score: {match['similarity']:.2f}\")\n",
    "                print(\"   Person Information:\")\n",
    "                for key, value in match['person_info'].items():\n",
    "                    print(f\"   - {key.capitalize()}: {value}\")\n",
    "\n",
    "        # Display the images\n",
    "        display_images(top_matches)\n",
    "\n",
    "    print(\"\\n\")  # Add a newline for better readability\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    " \n",
    " # Ensure consistent case in both extracted race and DataFrame\n",
    "    person_df['race'] = person_df['race'].str.lower()\n",
    "    person_df['sex'] = person_df['sex'].str.lower()  # Lowercase sex for consistent matching\n",
    "    Person_df['hair'] = person_df['hair'].str.lower()\n",
    "    person_df['eyes'] = person_df['eyes'].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Race mapping and filtering (case-insensitive)\n",
    "    race_mapping = {\n",
    "        'white': ['white', 'caucasian'],\n",
    "        'black': ['black', 'african'],\n",
    "        'asian': ['asian', 'east asian'],\n",
    "        'hispanic': ['hispanic', 'latino'],\n",
    "        'indian': ['indian', 'south asian']\n",
    "    }\n",
    "\n",
    "    if text_features['race']:\n",
    "        race_matched = False\n",
    "        for key, variants in race_mapping.items():\n",
    "            if text_features['race'].lower() in variants:\n",
    "                print(f\"Filtering by race: {key}\")\n",
    "                filtered_df = filtered_df[filtered_df['race'] == key]\n",
    "                race_matched = True\n",
    "                break\n",
    "        if not race_matched:\n",
    "            print(f\"Race '{text_features['race']}' did not match any known races.\")\n",
    "\n",
    "    # sex mapping and filtering (case-insensitive)\n",
    "    sex_mapping = {\n",
    "        'male': ['man', '']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)  # Change to DEBUG for more details\n",
    "\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.eval()\n",
    "resnet50 = torch.nn.Sequential(*(list(resnet50.children())[:-1]))\n",
    "\n",
    "# Image preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize NLP models\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def clean_description(desc):\n",
    "    non_facial_keywords = r'\\b(shirt|jeans|pants|shoes|hat|scarf|jacket|coat)\\b'\n",
    "    clean_desc = re.sub(non_facial_keywords, '', desc, flags=re.IGNORECASE)\n",
    "    \n",
    "    # General synonym mapping for gender, race, and other features\n",
    "    synonym_mapping = {\n",
    "        # Gender synonyms\n",
    "        'man': 'male',\n",
    "        'woman': 'female',\n",
    "        'lady': 'female',\n",
    "        'gentleman': 'male',\n",
    "        \n",
    "        # Race synonyms\n",
    "        'caucasian': 'white',\n",
    "        'african': 'black',\n",
    "        'latino': 'hispanic',\n",
    "        'east asian': 'asian',\n",
    "        'south asian': 'indian',\n",
    "        \n",
    "        # Hair color synonyms\n",
    "        'blonde': 'blonde hair',\n",
    "        'brunette': 'brown hair',\n",
    "        'redhead': 'red hair',\n",
    "\n",
    "        # Comprehensive synonym mapping for gender and race\n",
    "\n",
    "        'male': ['man', 'gentleman', 'boy'],\n",
    "        'female': ['woman', 'lady', 'girl'],\n",
    "        'white': ['white', 'caucasian'],\n",
    "        'black': ['black', 'african'],\n",
    "        'asian': ['asian', 'east asian'],\n",
    "        'hispanic': ['hispanic', 'latino'],\n",
    "        'indian': ['indian', 'south asian'],\n",
    "        \n",
    "        # Additional mappings can be added here for other features\n",
    "    }\n",
    "\n",
    "    # Replace synonyms in the description\n",
    "    for standard, variations in synonym_mapping.items():\n",
    "        for word in variations:\n",
    "            clean_desc = re.sub(rf'\\b{word}\\b', standard, clean_desc, flags=re.IGNORECASE)\n",
    "\n",
    "    return re.sub(r\"\\s+\", \" \", clean_desc).strip()\n",
    "    \n",
    "def extract_text_features(text):\n",
    "    text = clean_description(text)\n",
    "\n",
    "    feature_list = [\n",
    "        'male', 'female', 'young', 'middle-aged', 'elderly',\n",
    "        'blonde hair', 'brown hair', 'black hair', 'grey hair', 'white hair', 'red hair',\n",
    "        'blue eyes', 'green eyes', 'brown eyes', 'hazel eyes',\n",
    "        'bald', 'white', 'black', 'asian', 'hispanic', 'indian',\n",
    "        'tall', 'short', 'overweight', 'slim'\n",
    "    ]\n",
    "\n",
    "    logging.info(f\"Processing text: '{text}'\")\n",
    "    results = classifier(text, feature_list, multi_label=True)\n",
    "\n",
    "    # Set a higher confidence threshold to avoid conflicting features\n",
    "    confidence_threshold = 0.6\n",
    "    attributes = {\n",
    "        'sex': None,\n",
    "        'age': None,\n",
    "        'hair': None,\n",
    "        'eyes': None,\n",
    "        'height': None,\n",
    "        'race': None,\n",
    "        'weight': None\n",
    "    }\n",
    "\n",
    "    # Temporary dictionary to hold possible conflicting features\n",
    "    temp_attributes = {\n",
    "        'hair': [],\n",
    "        'age': [],\n",
    "        'height': []\n",
    "    }\n",
    "\n",
    "    for label, score in zip(results['labels'], results['scores']):\n",
    "        if score > confidence_threshold:\n",
    "            logging.debug(f\"Identified feature: {label} with confidence {score}\")\n",
    "            if label in ['male', 'female', 'man', 'lady', 'woman']:\n",
    "                attributes['sex'] = label\n",
    "            elif label in ['young', 'middle-aged', 'elderly']:\n",
    "                temp_attributes['age'].append((label, score))  # Collect age-related features\n",
    "            elif 'hair' in label:\n",
    "                temp_attributes['hair'].append((label.split()[0], score))  # Collect hair-related features\n",
    "            elif 'eyes' in label:\n",
    "                attributes['eyes'] = label.split()[0]\n",
    "            elif label in ['tall', 'short']:\n",
    "                temp_attributes['height'].append((label, score))  # Collect height-related features\n",
    "            elif label in ['overweight', 'slim']:\n",
    "                attributes['weight'] = label\n",
    "            elif label in ['white', 'black', 'asian', 'hispanic', 'indian']:\n",
    "                attributes['race'] = label\n",
    "\n",
    "    # Resolve conflicts by taking the feature with the highest confidence\n",
    "    if temp_attributes['hair']:\n",
    "        attributes['hair'] = max(temp_attributes['hair'], key=lambda x: x[1])[0]\n",
    "    if temp_attributes['age']:\n",
    "        attributes['age'] = max(temp_attributes['age'], key=lambda x: x[1])[0]\n",
    "    if temp_attributes['height']:\n",
    "        attributes['height'] = max(temp_attributes['height'], key=lambda x: x[1])[0]\n",
    "\n",
    "    logging.info(f\"Extracted features: {attributes}\")\n",
    "    return attributes\n",
    "\n",
    "\n",
    "def extract_image_features(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = preprocess(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = resnet50(img_tensor).squeeze().cpu().numpy()\n",
    "    return features\n",
    "\n",
    "def extract_features_for_samples(samples_folder):\n",
    "    image_features = {}\n",
    "    for filename in os.listdir(samples_folder):\n",
    "        image_path = os.path.join(samples_folder, filename)\n",
    "        if os.path.isfile(image_path):\n",
    "            features = extract_image_features(image_path)\n",
    "            image_features[filename] = features\n",
    "    return image_features\n",
    "\n",
    "def get_text_embedding(features):\n",
    "    description = \" \".join([f\"{key}: {value}\" for key, value in features.items() if value])\n",
    "    embedding = sentence_model.encode(description)\n",
    "    return embedding\n",
    "\n",
    "def compare_embeddings(text_embedding, image_embeddings):\n",
    "    # Project text_embedding to the same dimension as image_embeddings\n",
    "    text_embedding_projected = np.random.rand(image_embeddings.shape[1])\n",
    "    text_embedding_projected[:text_embedding.shape[0]] = text_embedding\n",
    "\n",
    "    similarities = cosine_similarity([text_embedding_projected], image_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:3]\n",
    "    return top_indices, similarities[top_indices]\n",
    "\n",
    "\n",
    "\n",
    "def filter_person_df_with_images(person_df, samples_folder):\n",
    "    \"\"\"\n",
    "    Filter the person DataFrame to only include entries for which\n",
    "    corresponding image files exist in the samples folder.\n",
    "    \"\"\"\n",
    "    existing_images = set(os.path.splitext(f)[0] for f in os.listdir(samples_folder) if f.endswith('.jpg'))\n",
    "    return person_df[person_df['id'].astype(str).isin(existing_images)]\n",
    "\n",
    "\n",
    "def match_description_to_images(description, samples_folder, person_df):\n",
    "    person_df = filter_person_df_with_images(person_df, samples_folder)\n",
    "\n",
    "    # Clean description with generalized synonym mapping\n",
    "    description = clean_description(description)\n",
    "\n",
    "    # Extract text features\n",
    "    text_features = extract_text_features(description)\n",
    "\n",
    "    # Print extracted gender and race, and available races/genders in DataFrame\n",
    "    print(f\"Extracted gender from description: {text_features['sex']}\")\n",
    "    print(f\"Extracted race from description: {text_features['race']}\")\n",
    "    print(f\"Unique races in the dataset: {person_df['race'].unique()}\")\n",
    "    print(f\"Unique genders in the dataset: {person_df['sex'].unique()}\")\n",
    "\n",
    " \n",
    "     # Ensure consistent case in both extracted race and DataFrame\n",
    "    person_df['race'] = person_df['race'].str.lower()\n",
    "    person_df['sex'] = person_df['sex'].str.lower()  \n",
    "    person_df['hair'] = person_df['hair'].str.lower()\n",
    "    person_df['eyes'] = person_df['eyes'].str.lower()\n",
    "\n",
    "    # Proceed with filtering\n",
    "    filtered_df = person_df.copy()\n",
    "\n",
    "    # Race mapping and filtering (case-insensitive)\n",
    "    race_mapping = {\n",
    "        'white': ['white', 'caucasian'],\n",
    "        'black': ['black', 'african'],\n",
    "        'asian': ['asian', 'east asian'],\n",
    "        'hispanic': ['hispanic', 'latino'],\n",
    "        'indian': ['indian', 'south asian']\n",
    "    }\n",
    "\n",
    "    if text_features['race']:\n",
    "        race_matched = False\n",
    "        for key, variants in race_mapping.items():\n",
    "            if text_features['race'].lower() in variants:\n",
    "                print(f\"Filtering by race: {key}\")\n",
    "                filtered_df = filtered_df[filtered_df['race'] == text_features['race'].lower()]\n",
    "                race_matched = True\n",
    "                break\n",
    "        if not race_matched:\n",
    "            print(f\"Race '{text_features['race']}' did not match any known races.\")\n",
    "            \n",
    "    print(f\"Filtered DataFrame for white women: \\n{filtered_df[['id', 'race', 'sex']].head()}\")\n",
    "\n",
    "\n",
    "    # Filter by gender/sex\n",
    "    if text_features['sex']:\n",
    "        filtered_df = filtered_df[filtered_df['sex'].str.lower() == text_features['sex'].lower()]\n",
    "\n",
    "    # Print the filtered DataFrame after race and gender filtering\n",
    "    print(f\"Filtered DataFrame after race and gender filtering:\\n{filtered_df[['id', 'race', 'sex']].head()}\")\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        print(\"No matches found after filtering.\")\n",
    "        return []\n",
    "\n",
    "\n",
    "    # Filter by gender/sex\n",
    "    if text_features['sex']:\n",
    "        filtered_df = filtered_df[filtered_df['sex'].str.lower() == text_features['sex'].lower()]\n",
    "\n",
    "    # Log the filtered DataFrame after gender filtering\n",
    "    logging.info(f\"Filtered DataFrame after gender filtering:\\n{filtered_df[['id', 'race', 'sex']].head()}\")\n",
    "    print(f\"Filtered DataFrame for white women: \\n{filtered_df[['id', 'race', 'sex']].head()}\")\n",
    "\n",
    "    # Further filtering logic\n",
    "    if text_features['hair']:\n",
    "        filtered_df = filtered_df[filtered_df['hair'].str.lower() == text_features['hair'].lower()]\n",
    "\n",
    "    if text_features['eyes']:\n",
    "        filtered_df = filtered_df[filtered_df['eyes'].str.lower() == text_features['eyes'].lower()]\n",
    "\n",
    "    # Log the final DataFrame after all filtering\n",
    "    logging.info(f\"Final DataFrame after all filtering:\\n{filtered_df[['id', 'race', 'sex']].head()}\")\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        logging.warning(\"No matches found after final filtering.\")\n",
    "        return []\n",
    "\n",
    "    # Continue with feature matching (unchanged from previous steps)\n",
    "    image_features = {}\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        image_path = os.path.join(samples_folder, f\"{row['id']}.jpg\")\n",
    "        if os.path.isfile(image_path):\n",
    "            features = extract_image_features(image_path)\n",
    "            image_features[row['id']] = features\n",
    "\n",
    "    if not image_features:\n",
    "        logging.warning(\"No image matches found after filtering.\")\n",
    "        return []\n",
    "\n",
    "    text_embedding = get_text_embedding(text_features)\n",
    "    image_embeddings = np.array(list(image_features.values()))\n",
    "    image_ids = list(image_features.keys())\n",
    "\n",
    "    top_indices, similarities = compare_embeddings(text_embedding, image_embeddings)\n",
    "\n",
    "    # Get top 3 matches\n",
    "    top_matches = []\n",
    "    for idx, similarity in zip(top_indices[:3], similarities[:3]):\n",
    "        image_id = image_ids[idx]\n",
    "        person_info = filtered_df[filtered_df['id'].astype(str) == str(image_id)].iloc[0].to_dict()\n",
    "\n",
    "        match_info = {\n",
    "            'image_name': f\"{image_id}.jpg\",\n",
    "            'image_path': os.path.join(samples_folder, f\"{image_id}.jpg\"),\n",
    "            'similarity': similarity,\n",
    "            'person_info': person_info\n",
    "        }\n",
    "        top_matches.append(match_info)\n",
    "\n",
    "    return top_matches\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def display_images(top_matches):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle(\"Top 3 Matched Images\", fontsize=16)\n",
    "\n",
    "    for i, match in enumerate(top_matches):\n",
    "        img = Image.open(match['image_path'])\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Match {i+1}\\nSimilarity: {match['similarity']:.2f}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    samples_folder = '/content/drive/MyDrive/sample_2'\n",
    "    person_df = pd.read_csv('/content/drive/MyDrive/person.csv', delimiter=';')\n",
    "\n",
    "    while True:\n",
    "        description = input(\"Enter a description of the person you're looking for (or 'quit' to exit): \")\n",
    "        if description.lower() == 'quit':\n",
    "            print(\"Thank you for using the person search system. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        top_matches = match_description_to_images(description, samples_folder, person_df)\n",
    "\n",
    "        if not top_matches:\n",
    "            print(\"No matches found for the given description.\")\n",
    "        else:\n",
    "            print(\"\\nTop 3 matched images:\")\n",
    "            for i, match in enumerate(top_matches, 1):\n",
    "                print(f\"\\n{i}. Image: {match['image_name']}\")\n",
    "                print(f\"   Similarity Score: {match['similarity']:.2f}\")\n",
    "                print(\"   Person Information:\")\n",
    "                for key, value in match['person_info'].items():\n",
    "                    print(f\"   - {key.capitalize()}: {value}\")\n",
    "\n",
    "        # Display the images\n",
    "        display_images(top_matches)\n",
    "\n",
    "    print(\"\\n\")  # Add a newline for better readability\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
